{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**# Neural Network Training Setup**  \n",
    "\n",
    "## **1. Review of Neural Networks**  \n",
    "- Single neuron operation: $$ y = f(\\sum w_ix_i + b) $$\n",
    "- Multi-layer networks and activation functions.\n",
    "\n",
    "## **2. Types of Problems Neural Networks Solve**  \n",
    "- **Classification**: (e.g., image classification, spam detection, loan approval).  \n",
    "- **Regression**: (e.g., weather forecasting, stock price prediction).  \n",
    "\n",
    "## **3. Designing a Neural Network**  \n",
    "- **Input layer**: Defined by the number of input features.  \n",
    "- **Output layer**: Defined by the expected output (probability for classification, real number for regression).  \n",
    "- **Hidden layers**: Chosen heuristically and can be adjusted based on performance.  \n",
    "\n",
    "## **4. Computations in a Neural Network**  \n",
    "- Weighted sum calculation: $$ z = \\sum w_ix_i + b $$  \n",
    "- Activation functions:  \n",
    "  - **ReLU**: $$ f(z) = \\max(0, z) $$\n",
    "  - **Sigmoid** (for classification output): $$ \\sigma(z) = \\frac{1}{1+e^{-z}} $$\n",
    "\n",
    "## **5. Training the Neural Network**  \n",
    "- **Forward propagation**: Computes output based on inputs and current weights.  \n",
    "- **Loss calculation**: Compares predicted output with actual labels.  \n",
    "- **Optimization using Gradient Descent**: Adjusts weights and biases to minimize loss.  \n",
    "  - Update rule: $$ w = w - \\alpha \\frac{\\partial L}{\\partial w} $$\n",
    "- Iterative updates to improve performance.  \n",
    "\n",
    "## **6. Final Model Deployment**  \n",
    "- After training, weights and biases are frozen for inference.  \n",
    "\n",
    "This sets up the foundation for upcoming discussions on optimization algorithms and advanced training techniques.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
