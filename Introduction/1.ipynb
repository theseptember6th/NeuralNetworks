{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Neural Networks From Scratch â€“ Lec 3: An Intuition on Neural Networks**\n",
    "\n",
    "This lecture is focused on developing an **intuitive understanding of neural networks**, which are at the core of deep learning. Below is a detailed breakdown of the key concepts covered in the lecture:\n",
    "\n",
    "---\n",
    "\n",
    "## **1. What is a Neural Network?**\n",
    "A **Neural Network (NN)** is a mathematical model inspired by the structure of the human brain. It consists of **neurons (nodes)** organized in **layers** that process information and learn patterns from data.\n",
    "\n",
    "### **Basic Components:**\n",
    "- **Neurons (Nodes):** Fundamental units that take inputs, apply weights, biases, and activation functions, and produce an output.\n",
    "- **Layers:**\n",
    "  - **Input Layer:** Takes in raw data.\n",
    "  - **Hidden Layers:** Perform intermediate computations.\n",
    "  - **Output Layer:** Produces final predictions or classifications.\n",
    "\n",
    "- **Weights:** Values that determine the importance of an input feature.\n",
    "- **Biases:** Extra parameters added to shift the activation function.\n",
    "- **Activation Function:** Introduces non-linearity (e.g., ReLU, Sigmoid).\n",
    "\n",
    "---\n",
    "\n",
    "## **2. How Does a Neural Network Process Information?**\n",
    "Each neuron follows this equation:\n",
    "\n",
    "$$\n",
    "\\text{Output} = \\text{Activation Function} \\left( \\sum (\\text{Input} \\times \\text{Weight}) + \\text{Bias} \\right)\n",
    "$$\n",
    "\n",
    "- Inputs are multiplied by corresponding **weights**.\n",
    "- A **bias** is added to the weighted sum.\n",
    "- The **activation function** is applied to introduce non-linearity.\n",
    "\n",
    "This process continues layer by layer until the **final output** is produced.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Understanding a Single Neuron**\n",
    "A single neuron is mathematically similar to a **linear equation**:\n",
    "\n",
    "$$\n",
    "y = mx + c\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\( x \\) is the input\n",
    "- \\( m \\) is the weight\n",
    "- \\( c \\) is the bias\n",
    "- \\( y \\) is the output\n",
    "\n",
    "But a real neural network contains **many neurons**, making it capable of learning **complex patterns**.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Layers in a Neural Network**\n",
    "- **Single-layer Network (Perceptron):** Only one layer, limited to simple linear problems.\n",
    "- **Multi-layer Network:** Stacks multiple layers (deep learning) to learn **complex functions**.\n",
    "\n",
    "Example of a **fully connected layer** (each neuron connects to every neuron in the next layer):\n",
    "\n",
    "$$\n",
    "\\mathbf{output} = \\text{activation}(\\mathbf{weights} \\cdot \\mathbf{input} + \\mathbf{bias})\n",
    "$$\n",
    "\n",
    "This is a **dot product** operation.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Why Use Activation Functions?**\n",
    "If a network only used linear operations, it would behave like a simple **linear regression model**. To learn **complex, non-linear relationships**, activation functions are required.\n",
    "\n",
    "Common activation functions:\n",
    "\n",
    "1. **ReLU (Rectified Linear Unit)**  \n",
    "   $$\n",
    "   f(x) = \\max(0, x)\n",
    "   $$\n",
    "   (used in most deep networks).\n",
    "\n",
    "2. **Sigmoid**  \n",
    "   $$\n",
    "   f(x) = \\frac{1}{1 + e^{-x}}\n",
    "   $$\n",
    "   (used for probabilities).\n",
    "\n",
    "3. **Tanh**  \n",
    "   $$\n",
    "   f(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\n",
    "   $$\n",
    "   (used in RNNs).\n",
    "\n",
    "---\n",
    "\n",
    "## **6. How Neural Networks Learn (Training Process)**\n",
    "### **Forward Propagation:**\n",
    "- Inputs flow **forward** through the network.\n",
    "- Each layer applies **weights, biases, and activation functions**.\n",
    "- The output layer gives the final prediction.\n",
    "\n",
    "### **Loss Function:**\n",
    "- Measures the difference between predicted and actual values.\n",
    "- Example: Mean Squared Error (MSE) for regression, Cross-Entropy Loss for classification.\n",
    "\n",
    "### **Backpropagation (Learning Process):**\n",
    "- **Error is propagated backward** through the network.\n",
    "- Weights are updated using **Gradient Descent** to reduce loss.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Why Do Neural Networks Work?**\n",
    "They can learn complex **patterns** by adjusting **weights and biases** to minimize error. The deeper the network, the more complex the patterns it can learn.\n",
    "\n",
    "### **Key Takeaways:**\n",
    "- Neural networks are made of **layers of neurons**.\n",
    "- Each neuron performs **a weighted sum, adds a bias, and applies an activation function**.\n",
    "- **Training** involves adjusting weights using **backpropagation** and **gradient descent**.\n",
    "- Activation functions allow for learning **non-linear** patterns.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
